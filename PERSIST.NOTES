##
# pseudocode for maintaining shared containers
##

open named_object
    init namehash accumulation
    while name fragments
        accumulate namehash
    finalize namehash
    convert to string suitable for filename
    open temp_namehash

    init content hash accumulation
    return handle

write handle acts
    write act to temp_namehash
    accumulate contenthash

close handle tempfile
    close temp namehash

    finalize contenthash
       convert to string suitable for filename

    if contenthash exists
	    rm tempfile
    else
	    mv tempfile contenthash
    fi

    if namehash exists
        error if not a link
        get oldcontenthash from namehash->oldcontenthash (ls -i namehash; find . -inum <inum>)
        rm namehash
        if oldcontenthash != contenthash
            decrement refcount to oldcontenthash
            if refount == 0
                rm oldcontenthash
                rm all derivatives of oldcontenthash
            fi
        fi
    fi
    ln contenthash namehash



- stat() will give the inode of a namehash, and the number of hardlinks

- if all the contenthash are in one directory,  then searching with readdir() can find
  the contenthash from the inode
        - expensive ... every close where a namehash already exists require and iteration of all
		contents directory entries  (i.e. through number of different containers)

	-- minimize cost by using scandir()
     

        names/namehash files
	contents/contenthash files   << hardlinked from namehash files
	derivatives/contenthash deivative files
            

- if softlinks were used instead then would need to implement reference counting outside of the file system


- ok, so using scandir() is likely low cost when compared to generating hashes...
